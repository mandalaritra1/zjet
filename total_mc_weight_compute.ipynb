{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3cfdcf2-311f-4d6f-84dd-c6f30728f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import time\n",
    "import coffea\n",
    "import uproot\n",
    "import hist\n",
    "import vector\n",
    "from coffea import util, processor\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import pickle\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26470c37-002f-472f-a2d7-9b488644e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.event_weight import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc2957a2-f984-4c0d-9b30-81f0e94099c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_maker_nanov9(testing=False, do_gen=True, client=None, prependstr = \"root://xcache/\",\n",
    "                          skimfilename=None, eras_mc = None, do_syst = False , dask = False, do_jk = False,\n",
    "                          do_herwig = False, do_background = False, fname_out = None, syst_list = None, jet_syst_list = None ): \n",
    "\n",
    "\n",
    "    if do_jk == True:\n",
    "        do_syst = False\n",
    "        do_gen = True\n",
    "        do_background = False\n",
    "    filedir = \"samples/\"\n",
    "\n",
    "    eras_data = [\n",
    "        'UL16NanoAOD', \n",
    "        'UL16NanoAODAPV', \n",
    "        'UL17NanoAOD', \n",
    "        'UL18NanoAOD'\n",
    "           ]\n",
    "    eras_mc = eras_mc\n",
    "    \n",
    "    \n",
    "    if not testing: \n",
    "        nworkers = 4\n",
    "        if do_syst or do_jk:\n",
    "            chunksize = 400000\n",
    "        else:\n",
    "            chunksize = 400000\n",
    "        maxchunks = None\n",
    "    elif dask and (client != None):\n",
    "        chunksize = 100000\n",
    "        maxchunks = None\n",
    "    else:\n",
    "        client = None\n",
    "        nworkers = 1\n",
    "        if do_gen: \n",
    "            chunksize = 400000\n",
    "        else:\n",
    "            chunksize=400000\n",
    "        maxchunks = 1\n",
    "\n",
    "    print(\"Chunk Size \", chunksize)\n",
    "    print(\"Max chunks\", maxchunks)\n",
    "    fileset = {}\n",
    "    if not testing: \n",
    "        \n",
    "        if do_gen and (not do_herwig) and (not do_background):\n",
    "            print(\"Running over PYTHIA MC\")\n",
    "            dy_mc_filestr = \"DYJetsToLL_M-50_HT_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8_%s_files.txt\"\n",
    "            #dy_mc_filestr = \"pythia_%s.txt\"\n",
    "\n",
    "            for era in eras_mc: \n",
    "                filename = filedir + dy_mc_filestr % (era)\n",
    "                with open(filename) as f:\n",
    "                    dy_mc_files = [prependstr + i.rstrip() for i in f.readlines() if i[0] != \"#\"  ] \n",
    "                    fileset[era] = dy_mc_files\n",
    "        elif do_gen and do_herwig:\n",
    "            print(\"Running over Herwig MC\")\n",
    "            dy_mc_filestr = \"DYJetsToLL_M-50_TuneCH3_13TeV-madgraphMLM-herwig7_%s.txt\"\n",
    "\n",
    "            for era in eras_mc: \n",
    "                filename = filedir + dy_mc_filestr % (era)\n",
    "                with open(filename) as f:\n",
    "                    dy_mc_files = [prependstr + i.rstrip() for i in f.readlines() if i[0] != \"#\"  ] \n",
    "                    fileset[era] = dy_mc_files\n",
    "        elif do_gen and do_background:\n",
    "            print(\"Running over Background\")\n",
    "            bg_cat_list = [ 'ww', 'wz', 'zz', 'ttjets']\n",
    "            for bg in bg_cat_list:\n",
    "                filestr = bg \n",
    "                for era in eras_mc:\n",
    "                    filename = filedir + filestr + era + \".txt\"\n",
    "                    with open(filename) as f:\n",
    "                        files =  [prependstr + i.rstrip() for i in f.readlines() if i[0] != \"#\"  ] \n",
    "                        fileset[bg + '_' +era] = files\n",
    "        else: \n",
    "            print(\"Running over Data\")\n",
    "\n",
    "            datasets_list = [#['SingleElectron_UL2016','SingleMuon_UL2016'],]\n",
    "                             ['SingleElectron_UL2016APV','SingleMuon_UL2016APV'],]\n",
    "                             #['SingleElectron_UL2017','SingleMuon_UL2017'],]\n",
    "                             #['EGamma_UL2018','SingleMuon_UL2018']]\n",
    "\n",
    "            fname_out_list = [#'2016',]\n",
    "                              '2016APV',]\n",
    "                              #'2017',]\n",
    "                              #'2018']\n",
    "            # datasets_data = [\n",
    "            #     'SingleElectron_UL2016APV',\n",
    "            #     'SingleElectron_UL2016',\n",
    "            #     'SingleElectron_UL2017',\n",
    "            #     'EGamma_UL2018',\n",
    "            #     'SingleMuon_UL2016APV',\n",
    "            #     'SingleMuon_UL2016',\n",
    "            #     'SingleMuon_UL2017',\n",
    "            #     'SingleMuon_UL2018',\n",
    "            # ]\n",
    "            \n",
    "            fileset_data_list = []\n",
    "            for datasets_data in datasets_list: \n",
    "                fileset = {}\n",
    "                for dataset in datasets_data: \n",
    "                    filename = filedir + dataset + '_NanoAODv9_files.txt'\n",
    "                    with open(filename) as f:\n",
    "                        data_files = [prependstr + i.rstrip() for i in f.readlines()  if i[0] != \"#\" ]\n",
    "                        fileset[dataset] = data_files\n",
    "                fileset_data_list.append(fileset)\n",
    "    else: \n",
    "        if do_gen :\n",
    "            if ( not do_herwig) and (not do_background):\n",
    "                filename = filedir+\"subset2016mc.txt\"\n",
    "                #fileset[\"UL2018\"] = [prependstr+'/store/mc/RunIISummer20UL18NanoAODv9/DYJetsToLL_M-50_TuneCP5_13TeV-amcatnloFXFX-pythia8/NANOAODSIM/106X_upgrade2018_realistic_v16_L1v1-v2/230000/00EA9563-5449-D24E-9566-98AE8E2A61AE.root']\n",
    "                with open(filename) as f:\n",
    "                    fileset[\"UL18NanoAODv9\"] = [prependstr + i.rstrip() for i in f.readlines() if i[0] != \"#\" ]\n",
    "            elif ( not do_herwig) and do_background:\n",
    "                print(\"Doing bg test\")\n",
    "                fileset[\"wz_2017\"] = [prependstr + \"/store/mc/RunIISummer20UL17NanoAODv9/WZ_TuneCP5_13TeV-pythia8/NANOAODSIM/20UL17JMENano_106X_mc2017_realistic_v9-v1/40000/90971D38-C407-F344-BEB8-834DE3231BFB.root\"]\n",
    "            else:\n",
    "                print(\"Doing Herwig Test\")\n",
    "                fileset[\"UL17NanoAODv9\"] = [prependstr + \"/store/mc/RunIISummer20UL16NanoAODv9/DYJetsToLL_M-50_TuneCH3_13TeV-madgraphMLM-herwig7/NANOAODSIM/20UL16JMENano_HerwigJetPartonBugFix_106X_mcRun2_asymptotic_v17-v1/40000/6C26A4DE-8CED-894A-87CC-595EDC0D694D.root\"]\n",
    "        else: \n",
    "            fileset[\"UL2018\"] = [prependstr + \"/store/data/Run2018A/SingleMuon/NANOAOD/UL2018_MiniAODv2_NanoAODv9_GT36-v1/2820000/FF8A3CD2-3F51-7A43-B56C-7F7B7B3158E3.root\"]\n",
    "\n",
    "                \n",
    "\n",
    "    if client == None:  \n",
    "        print(\"Fileset keys \", fileset.keys())\n",
    "\n",
    "        run = processor.Runner(\n",
    "            executor = processor.FuturesExecutor(compression=None, workers=nworkers),\n",
    "            schema=NanoAODSchema,\n",
    "            chunksize=chunksize,\n",
    "            maxchunks=maxchunks,\n",
    "            skipbadfiles=True\n",
    "        )\n",
    "    else: \n",
    "        run = processor.Runner(\n",
    "            executor = processor.DaskExecutor(client=client, \n",
    "                                              retries=10, \n",
    "                                              treereduction=40, \n",
    "                                              status=True),\n",
    "            schema=NanoAODSchema,\n",
    "            chunksize=chunksize,\n",
    "            maxchunks=maxchunks,\n",
    "            \n",
    "            skipbadfiles=True\n",
    "        )\n",
    "\n",
    "    \n",
    "    print(\"Running...\")\n",
    "    # print(fileset)\n",
    "    # if client == None or testing == True:\n",
    "    #     dataset_runnable, dataset_updated = preprocess(\n",
    "    #         fileset,\n",
    "    #         align_clusters=False,\n",
    "    #         step_size=100_000,\n",
    "    #         files_per_batch=1,\n",
    "    #         skip_bad_files=True,\n",
    "    #         save_form=False,\n",
    "    #     )\n",
    "    #     to_compute = apply_to_fileset(\n",
    "    #             QJetMassProcessor(do_gen=do_gen, skimfilename=skimfilename),\n",
    "    #             max_chunks(dataset_runnable, 1000),\n",
    "    #             schemaclass=NanoAODSchema,\n",
    "    #         )\n",
    "    #     (output, ) = dask.compute(to_compute) \n",
    "    def run_over_fileset(fileset, fname_out = fname_out):    \n",
    "        output = run(\n",
    "            fileset,\n",
    "            \"Events\",\n",
    "            processor_instance=QJetMassProcessor(do_gen=do_gen, skimfilename=skimfilename, do_syst = do_syst, do_background  = do_background,\n",
    "                                                 do_jk = do_jk, syst_list = syst_list, jet_syst_list = jet_syst_list ),\n",
    "        )\n",
    "    \n",
    "        print(\"Done running\")\n",
    "        if fname_out == None:\n",
    "            if do_gen:\n",
    "                if testing == False:\n",
    "                    if len(eras_mc)==1:\n",
    "                        fname_out = 'qjetmass_zjets_gen_'+eras_mc[0]+'_' +\"all_syst\" +'.pkl'\n",
    "                    else:\n",
    "                        fname_out = 'qjetmass_zjets_gen_'+'_' +\"all_syst\" +'.pkl'\n",
    "                else:\n",
    "                    fname_out = 'test_qjetmass_zjets_gen_'+eras_mc[0]+'_' +\"all_syst\" +'.pkl'\n",
    "            else:\n",
    "                if testing == True:\n",
    "                    fname_out = 'test_qjetmass_zjets_reco.pkl'\n",
    "                else:\n",
    "                    fname_out = 'qjetmass_zjets_reco.pkl'\n",
    "            if do_jk:\n",
    "                fname_out = 'jackknife_output.pkl'\n",
    "        with open(fname_out, \"wb\") as f:\n",
    "            pickle.dump( output, f )\n",
    "        print(fname_out ,\" was created.\")\n",
    "    if testing:\n",
    "        run_over_fileset(fileset)\n",
    "    elif ((not testing) & (not do_gen)):\n",
    "        print(\"Running over DATA\")\n",
    "\n",
    "        i_name = 0\n",
    "        for fileset in fileset_data_list:\n",
    "            if fname_out == None:\n",
    "                print(f\"Now using files from {fname_out_list[i_name]}\")\n",
    "                print(f\"Output file will be saved at {'outputs/data_'+fname_out_list[i_name] + '.pkl'}\")\n",
    "                run_over_fileset(fileset, fname_out = 'outputs/data_'+fname_out_list[i_name] + '.pkl')\n",
    "                i_name += 1\n",
    "            else:\n",
    "                print(f\"Now using files from {fname_out_list[i_name]}\")\n",
    "                print(f\"Output file will be saved at {fname_out}\")\n",
    "                run_over_fileset(fileset, fname_out = fname_out)\n",
    "                i_name += 1\n",
    "    else:\n",
    "        run_over_fileset(fileset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a71f160-eccb-48ac-82ca-0962d3c32b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "casa = False\n",
    "enable_dask = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6acbfa8a-c445-4dcd-a9ee-735d3b9e07e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01257817-eff1-48d2-a3e1-5d7956648795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from python.event_weight import *\n",
    "\n",
    "from python.smp_utils import *\n",
    "from python.cms_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d8159d2-d053-4ca3-9453-8cc664d79f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_dask:\n",
    "\n",
    "    if not casa:\n",
    "        from distributed import Client\n",
    "        from lpcjobqueue import LPCCondorCluster\n",
    "        \n",
    "        cluster = LPCCondorCluster(transfer_input_files = [ \"correctionFiles\", \"samples\", \"python\"], \n",
    "                                   ship_env = False,\n",
    "                                   memory = \"4GB\",\n",
    "                                   #cores = 2,\n",
    "                                  scheduler_options={\"dashboard_address\": \":2018\"})\n",
    "        cluster.adapt(minimum=1, maximum=600)\n",
    "        \n",
    "        \n",
    "        client = Client(cluster)\n",
    "        client\n",
    "    else:\n",
    "        from distributed import Client\n",
    "        from coffea_casa import CoffeaCasaCluster\n",
    "    \n",
    "        cluster = CoffeaCasaCluster(job_extra = {'transfer_input_files':[ \"correctionFiles\", \"samples\", \"python\"] }, memory=\"10 GiB\")\n",
    "        cluster.adapt(minimum=4, maximum=70)\n",
    "        client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0251f89-0a6b-4a15-af01-1e6c70c409a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_dask:\n",
    "    client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2eb052d4-34d4-4e39-85bf-ed511fffef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jet_systematics = ['nominal',  'JES_AbsoluteScaleUp', 'JES_AbsoluteScaleDown', \"JERUp\", \"JERDown\"]\n",
    "\n",
    "systematics = ['nominal', 'puUp'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9d3cc01-604b-4799-809f-08843e387df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size  400000\n",
      "Max chunks None\n",
      "Running over PYTHIA MC\n",
      "Running...\n",
      "Done running#############################] | 100% Completed | 15min 58.7s\u001b[2K\u001b[2K\n",
      "outputs/mc_weight.pkl  was created.\n",
      "Done running All\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "dask = enable_dask\n",
    "eras_mc =  ['UL16NanoAODv9', 'UL16NanoAODAPVv9', 'UL17NanoAODv9','UL18NanoAODv9']\n",
    "#eras_mc =  [ 'UL16NanoAODv9',  'UL16NanoAODAPVv9']\n",
    "if not dask:\n",
    "    client_1 = None\n",
    "else:\n",
    "    client_1 = client\n",
    "    \n",
    "#client= None\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    \n",
    "    \n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for era in eras_mc:\n",
    "        era = era\n",
    "    try:\n",
    "\n",
    "        response_maker_nanov9(testing = False, \n",
    "                              do_gen = True,\n",
    "                              client=client_1,\n",
    "                              prependstr=\"root://cmsxrootd.fnal.gov/\", \n",
    "                              eras_mc=eras_mc,\n",
    "                              do_syst = True, \n",
    "                              do_jk = False,  \n",
    "                              dask = dask, \n",
    "                              do_herwig = False,\n",
    "                              do_background = False,\n",
    "                              syst_list = systematics,\n",
    "                              jet_syst_list = jet_systematics,\n",
    "                              fname_out = 'outputs/mc_weight.pkl')\n",
    "        #response_maker_nanov9(testing=False, do_gen=False, client=client)\n",
    "        print(\"Done running All\")\n",
    "    except Exception as e:\n",
    "        with open(\"error_log.txt\", \"w\") as f:\n",
    "            f.write(\"An error occurred:\\n\")\n",
    "            f.write(str(e) + \"\\n\\n\")\n",
    "            f.write(\"Traceback:\\n\")\n",
    "            traceback.print_exc(file=f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04b2bb2a-fc3b-4deb-8a1f-dff248d60bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = 'outputs/mc_weight.pkl'\n",
    "import hist\n",
    "\n",
    "with open(filename3, 'rb') as f:\n",
    "    output3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb971d13-0eae-42c0-b57a-abe65d1e4c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UL16NanoAODv9': {'DYJetsToLL_M-50_HT-100to200_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 1110130.7963256836,\n",
       "               'total_weight': 1023872.1899035056}),\n",
       "  'DYJetsToLL_M-50_HT-800to1200_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 1991.3457907438278,\n",
       "               'total_weight': 1742.2257030465153}),\n",
       "  'DYJetsToLL_M-50_HT-400to600_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 17596.72917175293, 'total_weight': 15425.130866080872}),\n",
       "  'DYJetsToLL_M-50_HT-600to800_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 6004.06706237793, 'total_weight': 5232.713511637978}),\n",
       "  'DYJetsToLL_M-50_HT-2500toInf_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 4.707008833996952, 'total_weight': 3.9024592829422358}),\n",
       "  'DYJetsToLL_M-50_HT-1200to2500_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 634.6930615901947, 'total_weight': 555.73007504779}),\n",
       "  'DYJetsToLL_M-50_HT-200to400_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 239770.66442871094,\n",
       "               'total_weight': 215980.0632369077})},\n",
       " 'UL18NanoAODv9': {'DYJetsToLL_M-50_HT-600to800_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 14103.560745239258,\n",
       "               'total_weight': 12986.060659636985}),\n",
       "  'DYJetsToLL_M-50_HT-800to1200_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 9349.124026298523, 'total_weight': 8552.602748477142}),\n",
       "  'DYJetsToLL_M-50_HT-400to600_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 64610.03789138794, 'total_weight': 59782.48430041301}),\n",
       "  'DYJetsToLL_M-50_HT-200to400_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 767950.4626464844, 'total_weight': 716027.9337864302}),\n",
       "  'DYJetsToLL_M-50_HT-2500toInf_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 18.12699517607689, 'total_weight': 15.217230176282104}),\n",
       "  'DYJetsToLL_M-50_HT-1200to2500_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 1650.8187752962112, 'total_weight': 1483.583381629608}),\n",
       "  'DYJetsToLL_M-50_HT-100to200_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 3706027.5415039062,\n",
       "               'total_weight': 3476712.5477075814})},\n",
       " 'UL17NanoAODv9': {'DYJetsToLL_M-50_HT-600to800_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 9645.636236190796, 'total_weight': 8131.0939795958075}),\n",
       "  'DYJetsToLL_M-50_HT-800to1200_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 3665.687630176544, 'total_weight': 3105.679599276896}),\n",
       "  'DYJetsToLL_M-50_HT-200to400_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 491335.7495956421, 'total_weight': 431077.00497447536}),\n",
       "  'DYJetsToLL_M-50_HT-400to600_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 32278.25368499756, 'total_weight': 27436.129633020093}),\n",
       "  'DYJetsToLL_M-50_HT-2500toInf_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 9.984272299334407, 'total_weight': 7.927746882814545}),\n",
       "  'DYJetsToLL_M-50_HT-100to200_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 2558153.612915039, 'total_weight': 2307854.5837895037}),\n",
       "  'DYJetsToLL_M-50_HT-1200to2500_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 1163.5859798192978,\n",
       "               'total_weight': 988.3600326199978})},\n",
       " 'UL16NanoAODAPVv9': {'DYJetsToLL_M-50_HT-800to1200_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 3421.24161195755, 'total_weight': 2960.326306412932}),\n",
       "  'DYJetsToLL_M-50_HT-400to600_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 22077.856901168823,\n",
       "               'total_weight': 19500.052762539257}),\n",
       "  'DYJetsToLL_M-50_HT-600to800_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 4801.578357696533, 'total_weight': 4187.615011267849}),\n",
       "  'DYJetsToLL_M-50_HT-200to400_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 232873.89374542236, 'total_weight': 210603.370609125}),\n",
       "  'DYJetsToLL_M-50_HT-2500toInf_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 6.374174169264734, 'total_weight': 4.877415975959246}),\n",
       "  'DYJetsToLL_M-50_HT-1200to2500_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 538.2466237992048, 'total_weight': 456.47250417397527}),\n",
       "  'DYJetsToLL_M-50_HT-100to200_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8': defaultdict(int,\n",
       "              {'sumw': 1332903.4754333496,\n",
       "               'total_weight': 1227513.495570559})}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output3['cutflow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7addfc-fa7c-4f15-a07f-0dd67a18d305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
